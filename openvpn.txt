When installing openvpn on arch linux there is a conflict.

sudo pacman -S openvpn
resolving dependencies...
looking for conflicting packages...
:: systemd-libs and libsystemd are in conflict. Remove libsystemd? [y/N] y

Packages (3) libsystemd-239.0-2 [removal]  systemd-libs-241.93-1  openvpn-2.4.7-1

Total Download Size:   0.79 MiB
Total Installed Size:  2.67 MiB
Net Upgrade Size:      0.19 MiB

:: Proceed with installation? [Y/n] y


So I just said yes :)
Lets see what happens.

The result was fine, nothing broke as far as I can tell.

To run the client just run:
sudo openvpn --config /path/to/config.ovpn




What is a tun interface?
Packets sent by an operating system via a tun/tap device are delivered to a user-space program which attaches itself to the device. A user-space program may also pass packets into a tun/tap device. In this case the tun/tap device delivers (or “injects”) these packets to the operating-system network stack thus emulating their reception from an external source. tun/tap interfaces are software-only interfaces, meaning that they exist only in the kernel and, unlike regular network interfaces, they have no physical hardware component (and so there’s no physical wire connected to them).

You can think of a tun/tap interface as a regular network interface that, when the kernel decides that the moment has come to send data “on the wire”, instead sends data to some userspace program that is attached to the interface.


General overview of linux kernel networking. It uses netfilter architecture. Firewalls, routing and the like are implemented via hooks at various points in the protocol stack. The
protocol stack being the stack from OSI model layer 1 to layer 7. Where layer 1 is implemented in hardware, layers 2-4 in kernel and layer 5-7 in userspace.
https://netfilter.org/documentation/HOWTO/netfilter-hacking-HOWTO-3.html


Well lots of interesting info!

First of all openvpn dies in "fail open" mode. So one needs to implement a kill switch mechanism.
Otherwise the traffic will be exposed over the network! Why? Well if openvpn dies, then tun0 fails to send
then kernel will route trafic through another interface.

So what mechanisms are there?
Basically its the firewall. Block all LAN -> WAN traffic. Allow only LAN -> VPN traffic. Consider installing this firewall on the router together with openvpn client.
But if no router is availiable you can add failsafe mechanism anyway. Use local firewall.

For example install UFW on linux. Then deny all in/out traffic. Then allow only traffic on tun0 interface.
Then allow for all physical interface outgoing traffic on port 1194, to allow openvpn client to actually send out data on physical interface.

Then DNS is an issue. If you are connected by wifi, network manager will manage your /etc/resolv.conf. The nameserver in /etc/resolv.conf will typically be your
wifi access point (i.e. router) which has a local ip (like 192.168.1.1). This is a problem because when DNS traffic emerges from the other end of tun0 tunnel it of course
can not find the specified DNS server at 192.168.1.1. So either push a DNS setting via openvpn client config OR open up port 53 on physical interface. 
If pushing a setting consider googles DNS of 8.8.8.8 which has the disadvantage of being slow because its far away from you, or if OpenVPN server is also a
Bind9 server push its own ip address. Allowing outbound traffic on port 53, in my opinion ruins the point of routing everything over vpn.


Keep in mind that by default only IPv4 is tunneled. IPv6 needs special config on both client and server. The problem is that some ISP
(like russian mobile carrier MTS) provide IPv6, so when you are connected to such an ISP some applications will prefer IPv6.
This is a problem because IPv6 leaks into the open internet! In particular Firefox prefers to use IPv6 when it can! (see https://serverfault.com/questions/948051/openvpn-leaks-ipv6-in-ubuntu-but-not-in-android)

See this page for details of your IP and VPN functionallity: https://ipleak.net/

Also remember that DNS leaks might not sound like much, but if someone collects them thay can see the names of all the websites you visited. Because DNS stores address in plain text.

The decision whether to use IPv4 or 6 lies largely with the OS and the RFC for IPv6 specifies that IPv6 should be prefered.
see: https://askubuntu.com/questions/9181/how-to-let-the-browser-prefer-ipv6-over-ipv4
So there will be more and more ipv6 around soon. Better make OpenVPN server support the ipv6 tunnel.
Trying to firewall IPv4 to force all traffic through IPv4 tunnel seems short-sighted.

But! Not all hosting companies allow ipv6. And on some companies you have to edit /etc/network/interfaces to bring up the <global> ipv6 portion of the interface.. The ipv6 <link> interface is ususally there for most ihardware nterfaces.
How to edit /etc/network/interfaces to bring it up see: https://www.cyberciti.biz/faq/ubuntu-ipv6-networking-configuration/

Here is an example stanza:
# IPv6 interface
iface ens18 inet6 static
	address 2a00:b700:a::6:221
	netmask 64
	gateway 2a00:b700:a::1
	dns-nameservers 2a00:b700:a::220 2a00:b700:a:1::220

More about IPv6!
So by default every client in IPv6 network gets a /64 bits subnet. In case of configuring OpenVPN docker container we should split this
subnet in two to allow some for docker containers and some for what ever other uses.
see: https://docs.docker.com/v17.09/engine/userguide/networking/default_network/ipv6/

When you buy a vps the provider gives you a specific ipv6 address. However to comply with RFC they actually give you the whole subnet /64.
see: https://www.lowendtalk.com/discussion/27455/yes-you-can-use-the-whole-64-of-ipv6-on-ovhs-kimsufi
So you can actually ping the next address in the subnetwork that you were given out and reach it from the outside.

To understand how ipv6 allocation works see this IBM article:
https://www.ibm.com/support/knowledgecenter/en/STCMML8/com.ibm.storage.ts3500.doc/opg_3584_IPv4_IPv6_prefix_subnet_mask.html

When running openvpn docker container you must allocate a subnet of IPv6 to docker. Also know that docker documentation is currently wrong and just
enabling "ipv6":true in daemon.json will not work. See: https://github.com/moby/moby/issues/36954

So how to subnet then? Well docker needs at least /80 so give it to him. Lets say the ip address give to us by the vps provider is 2a00:b700:a::6:221 that means we actually have addresses:
from 2a00:b700:000a:0000:0000:0000:0000:0000
upto 2a00:b700:000a:0000:FFFF:FFFF:FFFF:FFFF
We will give docker a /80 subnet but prefix it with a 1 like this 2a00:b700:a:0:1::0/80 which means addresses:
from 2a00:b700:000a:0000:0001:0000:0000:0000
upto 2a00:b700:000a:0000:0001:FFFF:FFFF:FFFF

Well it was a long journey!

So I setup openvpn and all was well. Then I opened wireshark and noticed that if ipv6 was used the packets did not route through OpenVPN. They leaked!
That means that when you are by chance connected to an ipv6 enabled network all your traffic would leak, because actually modern OS prefere to use ipv6.
This had to be fixed! And the way to fix it was of course to enable ipv4 and ipv6 runneling in OpenVPN. Because ipv6 is on the rollout everywhere!

First of all lets back up some claims I make. Modern OS try to evaluate which is faster ipv4 or ipv6 and use that. They keyhole is the getaddrinfo function which
returns ipv6, ipv4 or both. The OS manipulates its return values to either provide the application with only ipv4, or only ipv6 or both (leaving up to the application to choose).
The getaddrinfo function can also be manipulated by /etc/gai.conf By editing that file you can make the OS prefer ipv4 over ipv6. But the default is ipv6.

So then I was off on a journey. To be honest most of the dance was around the ipv6 ISP and docker. The openvpn docker image was ready for ipv6.
But some adjustments had to be made. So talking about server openvpn config file. This is created by ovpn_genconfig script. Its important to understand
the difference between "route" and "push route" (a "route" directive takes a subnet (ip and netmask) upon an arrival of a package for this
subnet the server will put it on the tun device). Also its important to see how ipv4 is done and just repeat the steps for ipv6. For ipv4 there is
a "server" directive which specifies a subnet (ip and netmask).

So in case of ipv6 I created a special subnet of ipv6 addresses (a /64 subnet, because my vps provider gave me a /48). I set the server-ipv6 directive
to describe that subnet (ip and prefix length). Finally I added a 'push "route-ipv6 2000::/3"' so clients will route all internet traffic over tun0
interface.

So to be clear: an openvpn server gets a subnet (network A) from which it allocates ips for clients. Now some clients (client A) just use this subnet,
but some clients (client B) are gateways (router) to another network (network B). So this network B uses a different subnet from what the OpenVPN
server has. We can instruct the OpenVPN server that when it gets a packet destined to network B it will send it through tun0 interface (which means
that client B will be able to pick it up).
This is used if you have a network B which is ipv4 only and you want to access the internet via ipv6, so you tunnel to OpenVPN which has ipv6 enabled.
See: https://openoffice.nl/2018/04/05/ipv6-openvpn-part2/

Its really funny how there words like "route" sound so alien until you begin to understand it. Now this stuff is just so obvious.
It feels like I spend the last week mulling over things that are so obvious, clear and simple :)

Know that IPv6 are meant to be unique. So if your device is offline or online or its a local network in a random field that you have
setup, it does not matter, but the ipv6 is unique! When that device which is now in a local network in some field finally goes online
it will be the sole owner of that address, and I as the owner of the prefix have to guarantee that that device is the sole owner.

Some questions were raised as to how docker gets involved into the whole ipv6 thing. Well docker needs to have ipv6 enabled and needs
a subnet to assign ipv6 addresses to containers.

Here is how it looks like when ISP supports ipv6 and everything is ipv6:
Sun Jun 23 13:14:20 2019 TCP/UDP: Preserving recently used remote address: [AF_INET6]2a00:b700::6:220:1194
Sun Jun 23 13:14:20 2019 UDPv6 link local: (not bound)
Sun Jun 23 13:14:20 2019 UDPv6 link remote: [AF_INET6]2a00:b700::6:220:1194
Sun Jun 23 13:14:20 2019 [ansible.mysite.site] Peer Connection Initiated with [AF_INET6]2a00:b700::6:220:1194
Sun Jun 23 13:14:21 2019 TUN/TAP device tun0 opened
Sun Jun 23 13:14:21 2019 /usr/bin/ip link set dev tun0 up mtu 1500
Sun Jun 23 13:14:21 2019 /usr/bin/ip addr add dev tun0 local 192.168.255.6 peer 192.168.255.5
Sun Jun 23 13:14:21 2019 /usr/bin/ip -6 addr add 2a00:b700:0:feed::1000/64 dev tun0
Sun Jun 23 13:14:21 2019 add_route_ipv6(2a00:b700::6:220/128 -> fe80::9e5c:f9ff:fed4:8d2d metric 1) dev wlo1
Sun Jun 23 13:14:21 2019 add_route_ipv6(2000::/3 -> 2a00:b700:0:feed::1 metric -1) dev tun0
Sun Jun 23 13:14:21 2019 add_route_ipv6(::/3 -> 2a00:b700:0:feed::1 metric -1) dev tun0
Sun Jun 23 13:14:21 2019 add_route_ipv6(2000::/4 -> 2a00:b700:0:feed::1 metric -1) dev tun0
Sun Jun 23 13:14:21 2019 add_route_ipv6(3000::/4 -> 2a00:b700:0:feed::1 metric -1) dev tun0
Sun Jun 23 13:14:21 2019 add_route_ipv6(fc00::/7 -> 2a00:b700:0:feed::1 metric -1) dev tun0
Sun Jun 23 13:14:21 2019 WARNING: this configuration may cache passwords in memory -- use the auth-nocache option to prevent this
Sun Jun 23 13:14:21 2019 Initialization Sequence Completed

Here is how it looks like when your ISP does not support ipv6 (it falls back to ipv4):
Sun Jun 23 03:00:56 2019 TCP/UDP: Preserving recently used remote address: [AF_INET6]2a00:b700::6:220:1194
Sun Jun 23 03:00:56 2019 UDPv6 link local: (not bound)
Sun Jun 23 03:00:56 2019 UDPv6 link remote: [AF_INET6]2a00:b700::6:220:1194
Sun Jun 23 03:00:56 2019 write UDPv6: Network is unreachable (code=101)
Sun Jun 23 03:00:56 2019 Network unreachable, restarting
Sun Jun 23 03:00:56 2019 SIGUSR1[soft,network-unreachable] received, process restarting
Sun Jun 23 03:01:01 2019 TCP/UDP: Preserving recently used remote address: [AF_INET]185.22.153.49:1194
Sun Jun 23 03:01:01 2019 UDP link local: (not bound)
Sun Jun 23 03:01:01 2019 UDP link remote: [AF_INET]185.22.153.49:1194
Sun Jun 23 03:01:01 2019 [ansible.mysite.site] Peer Connection Initiated with [AF_INET]185.22.153.49:1194
Sun Jun 23 03:01:02 2019 Options error: Unrecognized option or missing or extra parameter(s) in [PUSH-OPTIONS]:1: block-outside-dns (2.4.7)
Sun Jun 23 03:01:02 2019 TUN/TAP device tun0 opened
Sun Jun 23 03:01:02 2019 /usr/bin/ip link set dev tun0 up mtu 1500
Sun Jun 23 03:01:02 2019 /usr/bin/ip addr add dev tun0 local 192.168.255.6 peer 192.168.255.5
Sun Jun 23 03:01:02 2019 /usr/bin/ip -6 addr add 2a00:b700:0:feed::1000/64 dev tun0
Sun Jun 23 03:01:02 2019 add_route_ipv6(2000::/3 -> 2a00:b700:0:feed::1 metric -1) dev tun0
Sun Jun 23 03:01:02 2019 add_route_ipv6(::/3 -> 2a00:b700:0:feed::1 metric -1) dev tun0
Sun Jun 23 03:01:02 2019 add_route_ipv6(2000::/4 -> 2a00:b700:0:feed::1 metric -1) dev tun0
Sun Jun 23 03:01:02 2019 add_route_ipv6(3000::/4 -> 2a00:b700:0:feed::1 metric -1) dev tun0
Sun Jun 23 03:01:02 2019 add_route_ipv6(fc00::/7 -> 2a00:b700:0:feed::1 metric -1) dev tun0
Sun Jun 23 03:01:02 2019 WARNING: this configuration may cache passwords in memory -- use the auth-nocache option to prevent this
Sun Jun 23 03:01:02 2019 Initialization Sequence Completed


For completeness here is the server openvpn config:
"""
server 192.168.255.0 255.255.255.0
verb 3
key /etc/openvpn/pki/private/ansible.mysite.site.key
ca /etc/openvpn/pki/ca.crt
cert /etc/openvpn/pki/issued/ansible.mysite.site.crt
dh /etc/openvpn/pki/dh.pem
tls-auth /etc/openvpn/pki/ta.key
key-direction 0
keepalive 10 60
persist-key
persist-tun

proto udp6
# Rely on Docker to do port mapping, internally always 1194
port 1194
dev tun0
status /tmp/openvpn-status.log

user nobody
group nogroup
client-to-client
comp-lzo

### Push Configurations Below
push "dhcp-option DNS 8.8.8.8"
push "dhcp-option DNS 8.8.4.4"

### Extra Configurations Below
server-ipv6 2a00:b700:0:feed::/64
push "route-ipv6 2000::/3"
duplicate-cn
"""

When the server is starting it has the following lines which describe its ip address pools:
Sat Jun 22 23:16:18 2019 IFCONFIG POOL IPv6: (IPv4) size=62, size_ipv6=65536, netbits=64, base_ipv6=2a00:b700:a:feed::1000
Sat Jun 22 23:16:18 2019 IFCONFIG POOL: base=192.168.255.4 size=62, ipv6=1

After your connection with openvpn server is established you can check it in various ways:
$ ip address show dev tun0
27: tun0: <POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UNKNOWN group default qlen 100
    link/none
    inet 192.168.255.6 peer 192.168.255.5/32 scope global tun0
       valid_lft forever preferred_lft forever
    inet6 2a00:b700:0:feed::1000/64 scope global
       valid_lft forever preferred_lft forever
    inet6 fe80::31d4:af94:b35b:f967/64 scope link stable-privacy
       valid_lft forever preferred_lft forever

$ ip route
0.0.0.0/1 via 192.168.255.5 dev tun0
default via 192.168.43.1 dev wlo1 proto dhcp src 192.168.43.248 metric 303
128.0.0.0/1 via 192.168.255.5 dev tun0
172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown
192.168.43.0/24 dev wlo1 proto dhcp scope link src 192.168.43.248 metric 303
192.168.255.0/24 via 192.168.255.5 dev tun0
192.168.255.5 dev tun0 proto kernel scope link src 192.168.255.6

$ ip -6 route
::1 dev lo proto kernel metric 256 pref medium
::/3 dev tun0 metric 1024 pref medium
2a00:1fa1:c6a0:77de::/64 dev wlo1 proto ra metric 303 mtu 1500 pref medium
2a00:1fa1:c6a0:77de::/64 dev wlo1 proto ra metric 600 pref medium
2a00:b700::6:220 via fe80::9e5c:f9ff:fed4:8d2d dev wlo1 metric 1 pref medium
2a00:b700:0:feed::/64 dev tun0 proto kernel metric 256 pref medium
2000::/4 dev tun0 metric 1024 pref medium
3000::/4 dev tun0 metric 1024 pref medium
2000::/3 dev tun0 metric 1024 pref medium
fc00::/7 dev tun0 metric 1024 pref medium
fe80::/64 dev wlo1 proto kernel metric 256 pref medium
fe80::/64 dev tun0 proto kernel metric 256 pref medium
fe80::/64 dev wlo1 proto kernel metric 600 pref medium
default via fe80::9e5c:f9ff:fed4:8d2d dev wlo1 proto ra metric 303 mtu 1500 pref medium
default via fe80::9e5c:f9ff:fed4:8d2d dev wlo1 proto ra metric 600 pref high

So we can see that tun0 interface has an IPv6 and IPv4.
We can see that there is a top route that sends all ipv4 to tun0
We can see that there is a ipv6 route on wlo1 which is because I am connected to a hotspot with ipv6, so reaching
device on the LAN I would just use wlo1 route. But for ipv6 internet 2000::/3 everything goes to tun0.

Here is the client config:
"""
client
nobind
dev tun
remote-cert-tls server

remote ansible.mysite.site 1194 udp6
remote ansible.mysite.site 1194 udp
redirect-gateway def1 ipv6

<key>
-----BEGIN PRIVATE KEY-----

-----END PRIVATE KEY-----
</key>
<cert>
-----BEGIN CERTIFICATE-----

-----END CERTIFICATE-----
</cert>
<ca>
-----BEGIN CERTIFICATE-----

-----END CERTIFICATE-----
</ca>
key-direction 1
<tls-auth>
#
# 2048 bit OpenVPN static key
#
-----BEGIN OpenVPN Static key V1-----

-----END OpenVPN Static key V1-----
</tls-auth>

comp-lzo
"""

Note that the client has a remote with udp6 and just udp. It will try ipv6 first and then fallback to ipv4.
The "redirect-gateway ipv6" is necessary because there is a bug in iOS 9 and Android. So its not necessary for desktop, but will not hurt.

So in the end I ran some tests.
One: I connected to an ipv6 enabled ISP and connected to my OpenVPN. In wireshark I could see that DNS queries went normally, while all other traffic
went over OpenVPN and used ipv6.
Two: I connected to an ipv4 only ISP and connected to OpenVPN. In wireshark I could see that all traffic went over OpenVPN and used ipv4.
